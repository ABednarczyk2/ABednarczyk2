#recreating Ramey
library(quantmod)
library(tidyverse)
library(quantmod)
library(readr)
library(lpirfs)
library(ggplot2)
library(dplyr)
# Download from FRED
getSymbols(c("INDPRO", "UNRATE", "CPIAUCSL", "FEDFUNDS", "GS1","BAMLH0A0HYM2EY"), 
           src = "FRED", 
           from = "1993-01-01", to = "2022-01-01")
#credit spreadsâ€”the difference in yields between various private debt instruments and government securities of comparable maturity
#i used ICE BofA US High Yield Index Effective Yield cause Gilchrist and Z only had until...2011? or something
#BAM needs to be monthly not daily
# Convert to monthly (last observation per month)
BAMLH0A0HYM2EY <- to.monthly(BAMLH0A0HYM2EY, indexAt = "lastof")

# Extract data
BAMLH0A0HYM2EY <- data.frame(
  date = index(BAMLH0A0HYM2EY),
  spread = coredata(BAMLH0A0HYM2EY$BAMLH0A0HYM2EY.Close)
)
head(BAMLH0A0HYM2EY)
#remember theres multiple values i think i should use "close date"
#nvm lets download again
library(quantmod)
library(dplyr)

getSymbols("BAMLH0A0HYM2EY", src = "FRED")

# Convert to monthly and keep ONLY the Close column
hy_monthly <- to.monthly(BAMLH0A0HYM2EY)[, "BAMLH0A0HYM2EY.Close"]

## Convert to data frame and rename columns
#hy_spread <- fortify.zoo(hy_monthly) %>% 
#  rename(date = Index, hy_spread = BAMLH0A0HYM2EY.Close)
#Ramey used logs of INDPRO and CPI 
#transform and merge
library(quantmod)
library(dplyr)

# Convert daily series to monthly (last observation)
 
HY_monthly <- to.monthly(BAMLH0A0HYM2EY, drop.time=TRUE)[, "BAMLH0A0HYM2EY.Close"]

data <- merge(INDPRO, UNRATE, CPIAUCSL, 
              FEDFUNDS, GS1, HY_monthly) %>%
  fortify.zoo() %>%
  rename(
    date = Index,  # THIS IS THE CRUCIAL FIX
    ffr = FEDFUNDS, gs1 = GS1, ebp = BAMLH0A0HYM2EY.Close) %>%
  mutate(
    lip = log(INDPRO),
    lcpi = log(CPIAUCSL)
  ) %>%
  select(date, lip, unemp = UNRATE, lcpi, ffr, gs1, ebp)

#converting Jarocinski to monthly
library(dplyr)
library(lubridate)

# Step 1: Clean and rename columns
u1_data <- U1bp %>%
  # Convert Time column to proper date (handling weird format)
  mutate(date = as.Date(Time, format = "%Y-%m-%d %H:%M:%S")) %>%
  # Keep only U1 and rename
  select(date, shock = u1) %>%
  # Remove rows with NA shocks
  filter(!is.na(shock))

# Step 2: Wieland-style monthly aggregation
u1_monthly <- u1_data %>%
  mutate(month = floor_date(date, "month")) %>%
  group_by(month) %>%
  summarize(
    N = n(),  # Number of days in month
    shock_sum = sum(shock),
    shock_wieland = shock_sum / sqrt(N)  # Volatility-adjusted
  ) %>%
  rename(date = month) %>%
  select(date, shock_wieland)

# Result (first 6 months)
head(u1_monthly)
ff4_tc<-copy(u1_monthly)
library(dplyr)
library(lubridate)

# Filter the dataset to 1997-2021
data_filtered <- data %>%
  filter(date >= as.Date("1996-12-01") & 
           date <= as.Date("2022-01-01"))
corn<-copy(data)
data<-copy(data_filtered)
data <- na.omit(data)
# Verify the date range
range(data_filtered$date)  # Should return: "1997-01-01" "2021-12-31"
#lp proper
library(lpirfs)
library(data.table)
library(lpirfs)

# Ensure your shock and instrument are one-column data frames
shock_df <- data.frame(ffr = data$ffr)
instrum_df <- data.frame(ff4_tc = data$ff4_tc)



shock_df <- data.frame(ffr = data$ffr)
instrum_df <- data.frame(ff4_tc = data$ff4_tc)

# Run the lp_lin_iv function

results <- lp_lin_iv(
  endog_data = data[, c("ffr", "lip", "unemp", "lcpi")],
  shock = shock_df,
  instrum = instrum_df,
  use_twosls = TRUE,
  lags_endog_lin = 2,
  hor = 24,
  confint = 1.68,
  trend = 1
)


plot(results)

# To plot specific variables:
plot_var(results, variables = "lip")  # Just industrial production
plot_var(results, variables = c("lip", "unemp"))  # Multiple variables

# Extract IRFs and confidence bands
irfs <- results$irf_lin
lower <- results$conf_int_lin[[1]]
upper <- results$conf_int_lin[[2]]

# Example: Plot IRF for 'lip'
plot(irfs$lip, type = "l", col = "blue", ylim = range(c(lower$lip, upper$lip)),
     ylab = "Response", xlab = "Horizon", main = "IRF: lip")
lines(lower$lip, col = "red", lty = 2)
lines(upper$lip, col = "red", lty = 2)
abline(h = 0, lty = 3)

# Example: IRF for 'unemp'
plot(irfs$unemp, type = "l", col = "blue", ylim = range(c(lower$unemp, upper$unemp)),
     ylab = "Response", xlab = "Horizon", main = "IRF: unemp")
lines(lower$unemp, col = "red", lty = 2)
lines(upper$unemp, col = "red", lty = 2)
abline(h = 0, lty = 3)

str(results)

#i get rhombuses :(

install.packages("AER")  # For ivreg()
install.packages("ivreg")  # Alternative package


library(AER)  # Load the package

# Correct first-stage specification
first_stage <- ivreg(ffr ~ lip + unemp + lcpi + ff4_tc | 
                       lip + unemp + lcpi + instrum_df$ff4_tc,
                     data = data)

# Get detailed summary including F-stat
summary(first_stage, diagnostics = TRUE)

# Check the structure of ff4_tc
str(instrum_df$ff4_tc)

# Convert from list to numeric if needed
instrum_df$ff4_tc <- unlist(instrum_df$ff4_tc)


# Check dimensions
nrow(data)  # Should match nrow(shock_df) and nrow(instrum_df)
nrow(shock_df)
nrow(instrum_df)

# Check if instrument exists in main data
"ff4_tc" %in% colnames(data)

# Check if you have the instrument variable anywhere
ls()  # List all objects in your environment

# Verify ff4_tc has correct length
length(ff4_tc) == nrow(data)  # Should be TRUE

# Add to main dataframe
data$ff4_tc <- ff4_tc

#my problem cause shocks are nt happening every month 
# Convert ff4_tc to dataframe if it isn't
if(!is.data.frame(ff4_tc)) {
  ff4_tc_df <- data.frame(date = names(ff4_tc), value = unlist(ff4_tc))
} else {
  ff4_tc_df <- ff4_tc
}

# Merge with main data
data <- merge(data, ff4_tc_df, by = "date", all.x = TRUE)

plot(ff4_tc_df$date, ff4_tc_df$shock_wieland, main = "Instrument Coverage")
abline(v = range(data$date), col = "red")




# After proper merging:
results <- lp_lin_iv(
  endog_data = data[, c("ffr", "lip", "unemp", "lcpi")],
  shock = data$ffr,
  instrum = data$ff4_tc,  # Now properly merged
  use_twosls = TRUE,
  lags_endog_lin = 3,
  hor = 24,
  confint = 1.68,
  trend = 1
)

# Check if ff4_tc exists as a separate object
exists("ff4_tc")  # Should return TRUE
length(ff4_tc)    # Confirm it has values (should be > 0)


# Compare lengths
nrow(data)    # Your main data (302 rows)
length(ff4_tc) # Your instrument (195 rows)

# Check if dates are in different formats
head(data$date)
head(names(ff4_tc))  # If it's a named vector
colnames(data)
data2<-copy(data)

library(dplyr)

# 1. Ensure all dates are proper Date objects
data$date <- as.Date(data$date)
ff4_tc$date <- as.Date(ff4_tc$date)

# 2. Create the instrument dataframe (now using the merged 'shock_wieland')
instrum_df <- data.frame(ff4_tc = data$shock_wieland)

# 3. Verify instrument alignment
cat("Instrument coverage:", sum(!is.na(data$shock_wieland)), "of", nrow(data), "observations\n")

# 4. Run the analysis with proper error handling
results <- tryCatch({
  lp_lin_iv(
    endog_data = data[, c("ffr", "lip", "unemp", "lcpi")],
    shock = data.frame(ffr_shock = data$ffr),  # Explicit shock df
    instrum = instrum_df,
    use_twosls = TRUE,
    lags_endog_lin = 3,
    hor = 24,
    confint = 1.68,
    trend = 1
  )
}, error = function(e) {
  message("Error in lp_lin_iv(): ", e$message)
  return(NULL)
})




# Check correlation between instrument and endogenous variables
cor_matrix <- cor(data[, c("shock_wieland", "ffr", "lip", "unemp", "lcpi")], 
                  use = "complete.obs")
print(cor_matrix)

# If |correlation| > 0.95 between shock_wieland and any other variable, you have collinearity
# no collinearity 
shock_wieland        ffr         lip       unemp       lcpi
shock_wieland    1.00000000 -0.1180422  0.08707073  0.06707925  0.1067400
ffr             -0.11804223  1.0000000 -0.22812907 -0.59345974 -0.6847713
lip              0.08707073 -0.2281291  1.00000000 -0.30769873  0.7169416
unemp            0.06707925 -0.5934597 -0.30769873  1.00000000  0.2045798
lcpi             0.10674002 -0.6847713  0.71694162  0.20457978  1.0000000

# Check if shock_wieland has zero variation in any month
zero_var_periods <- sapply(split(data$shock_wieland, format(data$date, "%Y-%m")), sd) == 0
sum(zero_var_periods)  # Count of months with constant shocks
#zero mths with constant shocs 


# Add microscopic noise (preserves economic meaning while fixing numerical instability)
set.seed(123)
data$shock_wieland <- data$shock_wieland + rnorm(nrow(data), sd = sd(data$shock_wieland)/1e6)
#Warning message:
#In rnorm(nrow(data), sd = sd(data$shock_wieland)/1e+06) : NAs produced





results <- lp_lin_iv(
  endog_data = data[, c("lip", "unemp", "lcpi")],  # Exclude ffr from endog
  shock = data$ffr,
  instrum = data.frame(instr = data$shock_wieland),
  use_twosls = FALSE,  # Try LIML instead of 2SLS
  lags_endog_lin = 2,  # Reduced lags
  hor = 24,
  confint = 1.68,
  trend = 0  # Try without trend
)#nothing not data>frame

# Check numerical rank of your design matrix
X <- cbind(1, data$shock_wieland, data$lip, data$unemp, data$lcpi) # Add constant
matrix_rank <- qr(X)$rank
required_rank <- ncol(X)
cat("Matrix rank:", matrix_rank, "/", required_rank, "\n")

data<-copy(data2)
#ok sth wron still
# Check NA patterns without 'mice'
na_summary <- sapply(data[, c("ffr", "lip", "unemp", "lcpi", "shock_wieland")], 
                     function(x) sum(is.na(x)))
print("NA Counts:")
print(na_summary)

# Check zero-variance columns
zero_var <- sapply(data[, c("ffr", "lip", "unemp", "lcpi", "shock_wieland")],
                   function(x) length(unique(x)) == 1)
print("Constant Columns:")
print(zero_var)

#the nas are the problem in wieland shocks 
# Check NA distribution
na_dates <- data$date[is.na(data$shock_wieland)]
cat("NAs occur in:", format(range(na_dates), "%Y-%m"), "\n")

# Visualize missingness
plot(data$date, is.na(data$shock_wieland), 
     type = "h", ylab = "Is NA", 
     main = "NA Values in shock_wieland")


# Filter to only rows with shocks
shock_data <- data[!is.na(data$shock_wieland), ]

# Verify shock distribution
cat("Shock count:", nrow(shock_data), "/", nrow(data), 
    "(", round(100*nrow(shock_data)/nrow(data),1), "%)\n")

# Plot shock timing
plot(shock_data$date, shock_data$shock_wieland,
     type="h", lwd=2, col="red",
     main="Sporadic Shock Events",
     ylab="Shock Magnitude", xlab="Date")

install.packages("lfe")
library(lfe)

# Create leads/lags around shocks
shock_data <- shock_data %>%
  mutate(event_time = 0) %>%  # Shock date = t=0
  complete(event_time = -12:12)  # Create window around shocks

# Estimate dynamic effects
event_study <- felm(lip ~ shock_wieland | ffr + unemp + lcpi, 
                    data = shock_data)
summary(event_study)
Call:
  felm(formula = lip ~ shock_wieland | ffr + unemp + lcpi, data = shock_data) 

Residuals:
  Min         1Q     Median         3Q        Max 
-6.432e-10  0.000e+00  0.000e+00  0.000e+00  6.432e-10 

Coefficients:
  Estimate Std. Error t value Pr(>|t|)
shock_wieland  -0.2029        NaN     NaN      NaN

Residual standard error: NaN on -152 degrees of freedom
(24 observations deleted due to missingness)
Multiple R-squared(full model):     1   Adjusted R-squared:     1 
Multiple R-squared(proj model): 0.174   Adjusted R-squared: 2.054 
F-statistic(full model):-3.178e+17 on 346 and -152 DF, p-value: NA 
F-statistic(proj model): -32.03 on 1 and -152 DF, p-value: NA 
*** Standard errors may be too high due to more than 2 groups and exactDOF=FALSE
# maybe collinear maybe sth bad

# Check shock distribution
shock_stats <- data %>%
  filter(!is.na(shock_wieland)) %>%
  summarise(
    N = n(),
    Mean = mean(shock_wieland),
    SD = sd(shock_wieland),
    Unique = n_distinct(shock_wieland)
  )
print(shock_stats)

# Expected: SD > 0 and Unique > 1

# Keep only valid shock periods
shock_data <- data %>% 
  filter(!is.na(shock_wieland)) %>%
  mutate(time = dense_rank(date))  # Create time index

# Verify
nrow(shock_data)  # Should match shock_stats$N (195)
library(ivreg)
iv_model <- ivreg(
  lip ~ ffr + unemp + lcpi | 
    shock_wieland + unemp + lcpi,
  data = shock_data
)

# Check diagnostics
summary(iv_model, diagnostics = TRUE)




library(ggplot2)
ggplot(shock_data, aes(x = date)) +
  geom_line(aes(y = scale(ffr)), color = "black", linewidth = 1) +
  geom_col(aes(y = scale(shock_wieland)), fill = "red", alpha = 0.5, width = 5, na.rm = TRUE) +
  labs(
    title = "FFR vs. Monetary Policy Shocks",
    subtitle = "Red bars show the shock magnitudes",
    y = "Standardized values",
    x = "Date"
  ) +
  theme_minimal()


# First, create a new column for FFR changes
shock_data <- shock_data %>%
  mutate(ffr_change = c(NA, diff(ffr)))

# Now, plot the scatter plot with shock_wieland vs. ffr_change (using one color)
ggplot(shock_data, aes(x = shock_wieland, y = ffr_change)) +
  geom_point(color = "blue", size = 2) +  # Use one color (blue)
  labs(
    title = "FFR Changes vs. Monetary Policy Shocks",
    x = "Shock Magnitude",
    y = "FFR Change"
  ) +
  theme_minimal()



ggplot(data, aes(x = shock_wieland, y = ffr_change)) +
  geom_point(aes(color = ifelse(shock_wieland > 0, "red", "blue"))) + # Set color based on shock_wieland
  geom_smooth(method = "lm", se = FALSE, color = "black", na.rm = TRUE) +
  labs(
    title = "FFR Changes vs. Monetary Policy Shocks",
    x = "Shock Magnitude",
    y = "FFR Change",
    color = "Shock Size"
  ) +
  theme_minimal()



library(sandwich)
library(lmtest)

# Set horizon (e.g., 24 months)
horizon <- 24
lp_results <- list()

for (h in 0:horizon) {
  # Create leaded dependent variable
  shock_data[[paste0("lip_lead", h)]] <- dplyr::lead(shock_data$lip, h)
  
  # Estimate LP equation
  lp_results[[h+1]] <- lm(as.formula(paste0("lip_lead", h, " ~ shock_wieland")),
                          data = shock_data)
  
  # Add robust standard errors
  lp_results[[h+1]]$vcov <- vcovHAC(lp_results[[h+1]])
}

# Extract coefficients
irf <- sapply(lp_results, function(x) coef(x)["shock_wieland"])


# Create results dataframe
irf_df <- data.frame(
  horizon = 0:horizon,
  effect = sapply(lp_results, function(x) coef(x)["shock_wieland"]),
  se = sapply(lp_results, function(x) sqrt(diag(vcovHAC(x)))["shock_wieland"])
)

# Plot
ggplot(irf_df, aes(x = horizon, y = effect)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_ribbon(aes(ymin = effect - 1.96*se, ymax = effect + 1.96*se), 
              alpha = 0.2) +
  geom_line(color = "blue", linewidth = 1) +
  geom_point(color = "red") +
  labs(
    title = "Dynamic Effects of Monetary Policy Shocks",
    subtitle = "Local projection using shock periods only",
    x = "Months After Shock",
    y = "Effect on Industrial Production"
  )





# Keep only shock periods and create lags
shock_data <- data %>%
  filter(!is.na(shock_wieland)) %>%
  mutate(across(c(lip, unemp, lcpi, ffr), 
                list(lag1 = ~lag(.x, 1), lag2 = ~lag(.x, 2)), 
                .names = "{.col}_{.fn}")) %>%
  na.omit()  # Drop rows with missing lags

# Verify
cat("Using", nrow(shock_data), "shock periods with complete data\n")
library(sandwich)
library(lmtest)

horizon <- 24  # Response horizon in months
lp_results <- list()

for (h in 0:horizon) {
  # Create leaded dependent variable
  shock_data[[paste0("lip_lead", h)]] <- dplyr::lead(shock_data$lip, h)
  
  # Estimate LP equation
  lp_formula <- paste0(
    "lip_lead", h, " ~ shock_wieland + ",
    "ffr + unemp + lcpi + ",  # Contemporary controls
    "ffr_lag1 + unemp_lag1 + lcpi_lag1 + ",  # Lagged controls
    "ffr_lag2 + unemp_lag2 + lcpi_lag2"  # Additional lags
  )
  
  lp_results[[h+1]] <- lm(as.formula(lp_formula), data = shock_data)
  
  # Store robust standard errors
  lp_results[[h+1]]$vcov <- vcovHAC(lp_results[[h+1]])
}
# Extract shock coefficients and SEs
irf_df <- data.frame(
  horizon = 0:horizon,
  effect = sapply(lp_results, function(x) coef(x)["shock_wieland"]),
  se = sapply(lp_results, function(x) sqrt(x$vcov["shock_wieland", "shock_wieland"]))
)

# Plot
library(ggplot2)
ggplot(irf_df, aes(x = horizon, y = effect)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_ribbon(aes(ymin = effect - 1.96*se, ymax = effect + 1.96*se), alpha = 0.2) +
  geom_line(color = "blue", linewidth = 1) +
  geom_point(color = "red") +
  labs(
    title = "Dynamic Effects of Monetary Policy Shocks",
    subtitle = "Controlling for FFR, Unemployment, and CPI",
    x = "Months After Shock",
    y = "Effect on Industrial Production"
  )


library(lpirfs)

# Ensure shock_data contains your instrument (e.g., ff4_tc or ebp)
shock_data <- data %>% 
  filter(!is.na(shock_wieland))  # Keep only shock periods
results <- lp_lin_iv(
  endog_data = data[, c("ffr", "lip", "unemp", "lcpi")],
  shock = shock_df,
  instrum = instrum_df,
  use_twosls = TRUE,
  lags_endog_lin = 2,
  hor = 24,
  confint = 1.68,
  trend = 1
)


plot(results)

# Run the lp_lin_iv function
shock_data <- data %>% 
filter(!is.na(shock_wieland))

results <- lp_lin_iv(
  endog_data = data[, c("ffr", "lip", "unemp", "lcpi")],
  shock = shock_df,
  instrum = instrum_df,
  use_twosls = TRUE,
  lags_endog_lin = 2,
  hor = 24,
  confint = 1.68,
  trend = 1
)

plot(results)
# To plot specific variables:
plot_var(results, variables = "lip")  # Just industrial production
plot_var(results, variables = c("lip", "unemp"))  # Multiple variables

# Extract IRFs and confidence bands
irfs <- results$irf_lin
lower <- results$conf_int_lin[[1]]
upper <- results$conf_int_lin[[2]]

# Example: Plot IRF for 'lip'
plot(irfs$lip, type = "l", col = "blue", ylim = range(c(lower$lip, upper$lip)),
     ylab = "Response", xlab = "Horizon", main = "IRF: lip")
lines(lower$lip, col = "red", lty = 2)
lines(upper$lip, col = "red", lty = 2)
abline(h = 0, lty = 3)

# Example: IRF for 'unemp'
plot(irfs$unemp, type = "l", col = "blue", ylim = range(c(lower$unemp, upper$unemp)),
     ylab = "Response", xlab = "Horizon", main = "IRF: unemp")
lines(lower$unemp, col = "red", lty = 2)
lines(upper$unemp, col = "red", lty = 2)
abline(h = 0, lty = 3)

str(results)
